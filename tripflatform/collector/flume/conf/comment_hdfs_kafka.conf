#需求
# agent接收avro流数据,把数据一份发送到hdfs上储存,一份放入kafka进行流计算

a1.sources = s1
a1.sinks = k1 k2
a1.channels = c1 c2

a1.sources.s1.type = avro
a1.sources.s1.bind = master
a1.sources.s1.port = 8888

a1.channels.c1.type = memory
a1.channels.c2.type = memory


a1.sinks.k1.type = hdfs
a1.sinks.k1.hdfs.path = /comment/%Y%m%d
a1.sinks.k1.hdfs.fileSuffix = .log
a1.sinks.k1.hdfs.rollInterval = 0
a1.sinks.k1.hdfs.rollSize = 0
a1.sinks.k1.hdfs.rollCount = 0
a1.sinks.k1.hdfs.useLocalTimeStamp = true
a1.sinks.k1.hdfs.writeFormat = Text
a1.sinks.k1.hdfs.fileType = DataStream

a1.sinks.k2.type = org.apache.flume.sink.kafka.KafkaSink
a1.sinks.k2.kafka.bootstrap.servers = master:9092 slave1:9092 slave2:9092
a1.sinks.k2.kafka.topic = comment

a1.sources.s1.channels = c1 c2
a1.sinks.k1.channel = c1
a1.sinks.k2.channel = c2

#kafka-server-start.sh /opt/SoftWare/kafka_2.11-1.0.0/config/server.properties & 3节点都要开
#flume-ng agent -c conf -f comment_hdfs_kafka.conf --name a1